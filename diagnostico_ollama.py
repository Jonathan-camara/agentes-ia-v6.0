#!/usr/bin/env python3
"""
Script de diagn√≥stico para Ollama
Detecta y muestra todos los modelos disponibles
"""

import requests
import json
import sys

def diagnosticar_ollama():
    print("üîç DIAGN√ìSTICO DE OLLAMA")
    print("=" * 50)
    
    # Verificar conexi√≥n
    try:
        print("üì° Verificando conexi√≥n a Ollama...")
        response = requests.get('http://localhost:11434/api/tags', timeout=10)
        print(f"‚úÖ Estado de respuesta: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"‚úÖ Ollama est√° funcionando correctamente")
            print(f"üìä Respuesta completa: {json.dumps(data, indent=2)}")
            
            modelos = data.get('models', [])
            print(f"\nü§ñ MODELOS DETECTADOS: {len(modelos)}")
            print("-" * 30)
            
            if modelos:
                for i, modelo in enumerate(modelos, 1):
                    nombre = modelo.get('name', 'Sin nombre')
                    tamano = modelo.get('size', 0)
                    modificado = modelo.get('modified_at', 'Desconocido')
                    
                    # Convertir tama√±o
                    if tamano > 1024**3:  # GB
                        tamano_str = f"{tamano / (1024**3):.1f} GB"
                    elif tamano > 1024**2:  # MB
                        tamano_str = f"{tamano / (1024**2):.1f} MB"
                    else:
                        tamano_str = f"{tamano} bytes"
                    
                    print(f"{i}. {nombre}")
                    print(f"   üìè Tama√±o: {tamano_str}")
                    print(f"   üìÖ Modificado: {modificado}")
                    print(f"   üîß Detalles: {modelo.get('details', {})}")
                    print()
            else:
                print("‚ùå No se encontraron modelos")
                
        else:
            print(f"‚ùå Error de conexi√≥n: {response.status_code}")
            print(f"üìÑ Respuesta: {response.text}")
            
    except requests.exceptions.ConnectionError:
        print("‚ùå No se puede conectar a Ollama en puerto 11434")
        print("üí° Verifica que Ollama est√© ejecut√°ndose:")
        print("   - Windows: Busca 'Ollama' en el men√∫ inicio")
        print("   - Terminal: ollama serve")
        
    except requests.exceptions.Timeout:
        print("‚è±Ô∏è Timeout conectando a Ollama")
        
    except Exception as e:
        print(f"‚ùå Error inesperado: {e}")
    
    # Verificar proceso
    print("\nüîç VERIFICANDO PROCESO...")
    try:
        import subprocess
        import platform
        
        sistema = platform.system().lower()
        
        if sistema == 'windows':
            result = subprocess.run(['tasklist', '/FI', 'IMAGENAME eq ollama.exe'], 
                                  capture_output=True, text=True)
            if 'ollama.exe' in result.stdout:
                print("‚úÖ Proceso ollama.exe est√° ejecut√°ndose")
            else:
                print("‚ùå Proceso ollama.exe NO est√° ejecut√°ndose")
                print("üí° Inicia Ollama manualmente")
        else:
            result = subprocess.run(['pgrep', '-f', 'ollama'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                print("‚úÖ Proceso ollama est√° ejecut√°ndose")
            else:
                print("‚ùå Proceso ollama NO est√° ejecut√°ndose")
    except Exception as e:
        print(f"‚ùå Error verificando proceso: {e}")

if __name__ == "__main__":
    diagnosticar_ollama()

